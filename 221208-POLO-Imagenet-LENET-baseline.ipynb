{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from LogGabor import LogGabor\n",
    "from utils import view_data\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.offset_max = 40 #like in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "\n",
    "transform =  transforms.Compose([\n",
    "            transforms.Resize((int(image_size), int(image_size))),\n",
    "            #transforms.AutoAugment(), # https://pytorch.org/vision/master/transforms.html#torchvision.transforms.AutoAugment\n",
    "            transforms.ToTensor(),      # Convert the image to pyTorch Tensor data type.\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../data/animal/\"\n",
    "\n",
    "image_dataset = { 'train' : datasets.ImageFolder(\n",
    "                            image_path+'train', \n",
    "                            transform=transform\n",
    "                        ),\n",
    "                  'test' : datasets.ImageFolder(\n",
    "                            image_path+'test', \n",
    "                            transform=transform\n",
    "                        )\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1200)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = {'train' : len(image_dataset['train']),\n",
    "                'test' : len(image_dataset['test'])}\n",
    "\n",
    "dataset_size['train'], dataset_size['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_workers = 1\n",
    "\n",
    "dataloader = { 'train' : torch.utils.data.DataLoader(\n",
    "                            image_dataset['train'], batch_size=batch_size,\n",
    "                            shuffle=True, \n",
    "                            num_workers=num_workers,\n",
    "                        ),\n",
    "               'test' : torch.utils.data.DataLoader(\n",
    "                            image_dataset['test'], batch_size=batch_size,\n",
    "                            shuffle=True, \n",
    "                            num_workers=num_workers,\n",
    "                        )\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The original format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Attention Transformer model with log-polar entry (POLO-STN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polo_AttentionTransNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Polo_AttentionTransNet, self).__init__()\n",
    "\n",
    "        ##  The what pathway\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 2)\n",
    "\n",
    "\n",
    "        self.downscale = nn.Parameter(torch.tensor([[.2, 0], [0, .2]], dtype=torch.float), requires_grad=False)\n",
    "\n",
    "    def stn(self: object, x:torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        mu = torch.tensor([0, 0],dtype=torch.float)\n",
    "        mu = mu.unsqueeze(0).repeat(x.size()[0], 1)   \n",
    "        std = np.exp(-3/2)\n",
    "        sigma = torch.tensor([std, std],dtype=torch.float)\n",
    "        sigma = sigma.unsqueeze(0).repeat(x.size()[0], 1)   \n",
    "              \n",
    "        self.q = torch.distributions.Normal(mu, sigma)\n",
    "        z = self.q.rsample()\n",
    "        print(z[0])\n",
    "        \n",
    "        theta = torch.cat((self.downscale.unsqueeze(0).repeat(x.size(0), 1, 1), \n",
    "                           z.unsqueeze(2)),\n",
    "                            dim=2)\n",
    "        \n",
    "        grid_size = torch.Size([x.size()[0], x.size()[1], 28, 28])\n",
    "        grid = F.affine_grid(theta, grid_size)\n",
    "        x = F.grid_sample(x, grid)\n",
    "       \n",
    "        return x, theta, z\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x, theta, z = self.stn(x)                                   \n",
    "\n",
    "        # print(x.shape)\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "        x = x.view(-1, 4 * 4 * 50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x, theta, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device, dtype=torch.double), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, theta, z = model(data)\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, n_epochs, batch_idx * len(data),\n",
    "                len(dataloader['train'].dataset),\n",
    "                100. * batch_idx / len(dataloader['train']), loss.item()))\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device, dtype=torch.double), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output, theta, z = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            #test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            test_loss += loss_func(output, target).item()\n",
    "            # get the index of the max log-probability\n",
    "            #pred = output.max(1, keepdim=True)[1]\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(dataloader['test'].dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.\n",
    "              format(test_loss, correct, len(dataloader['test'].dataset),\n",
    "                     100. * correct / len(dataloader['test'].dataset)))\n",
    "        return correct / len(dataloader['test'].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "log_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = torch.load(\"../models/low_comp_polo_stn.pt\")\n",
    "model = Polo_AttentionTransNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9, last_epoch=-1) #, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1019, 0.2776])\n",
      "Train Epoch: 0/100 [0/2000 (0%)]\tLoss: 0.692487\n",
      "tensor([-0.0268, -0.3799])\n",
      "tensor([-0.1220,  0.1738])\n",
      "tensor([0.0372, 0.1412])\n",
      "tensor([0.0736, 0.1394])\n",
      "tensor([-0.0076,  0.2421])\n",
      "tensor([0.0826, 0.2255])\n",
      "tensor([-0.2906, -0.1683])\n",
      "tensor([0.1116, 0.0828])\n",
      "tensor([-0.3784, -0.0180])\n",
      "tensor([-0.0310,  0.0845])\n",
      "tensor([0.0591, 0.0487])\n",
      "tensor([-0.0926,  0.0868])\n",
      "tensor([-0.0143,  0.3228])\n",
      "tensor([-0.0347, -0.2162])\n",
      "tensor([ 0.2330, -0.3177])\n",
      "tensor([-0.0664,  0.0149])\n",
      "tensor([-0.0299,  0.1847])\n",
      "tensor([-0.2768, -0.3199])\n",
      "tensor([0.1915, 0.0041])\n",
      "tensor([ 0.4675, -0.0697])\n",
      "tensor([-0.1199, -0.1278])\n",
      "tensor([-0.1662, -0.2571])\n",
      "tensor([-0.3072,  0.1417])\n",
      "tensor([ 0.3294, -0.1055])\n",
      "tensor([-0.0003, -0.0719])\n",
      "tensor([0.3138, 0.3982])\n",
      "tensor([ 0.1455, -0.1690])\n",
      "tensor([-0.1028,  0.2212])\n",
      "tensor([0.1042, 0.2828])\n",
      "tensor([-0.0520,  0.0492])\n",
      "tensor([ 0.0715, -0.0718])\n",
      "tensor([-0.4023,  0.1579])\n",
      "tensor([-0.2272, -0.0321])\n",
      "tensor([-0.2465,  0.0348])\n",
      "tensor([ 0.1591, -0.0505])\n",
      "tensor([ 0.1451, -0.1796])\n",
      "tensor([-0.1259, -0.4493])\n",
      "tensor([0.1975, 0.0247])\n",
      "tensor([-0.5318, -0.0054])\n",
      "tensor([-0.1955,  0.4492])\n",
      "tensor([-0.0194,  0.0448])\n",
      "tensor([ 0.0115, -0.1447])\n",
      "tensor([-0.1762,  0.0473])\n",
      "tensor([0.5419, 0.1321])\n",
      "tensor([-0.3363, -0.2386])\n",
      "tensor([-0.0626,  0.0826])\n",
      "tensor([-0.2850, -0.1825])\n",
      "tensor([-0.3651, -0.0684])\n",
      "tensor([ 0.1241, -0.2450])\n",
      "tensor([0.2871, 0.2430])\n",
      "tensor([-0.2817, -0.1561])\n",
      "tensor([-0.2009,  0.1075])\n",
      "tensor([-0.3841, -0.3552])\n",
      "tensor([-0.0927, -0.0139])\n",
      "tensor([-0.1840, -0.0103])\n",
      "tensor([ 0.1348, -0.2142])\n",
      "tensor([-0.2980, -0.2878])\n",
      "tensor([0.1131, 0.1828])\n",
      "tensor([-0.0479, -0.0986])\n",
      "tensor([-0.0808,  0.1787])\n",
      "tensor([-0.1591,  0.2575])\n",
      "tensor([-0.4028, -0.0513])\n",
      "tensor([ 0.2273, -0.3510])\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 619/1200 (52%)\n",
      "\n",
      "tensor([0.2945, 0.1303])\n",
      "Train Epoch: 1/100 [0/2000 (0%)]\tLoss: 0.691237\n",
      "tensor([0.3235, 0.1607])\n",
      "tensor([0.0565, 0.1860])\n",
      "tensor([-0.4475, -0.0052])\n",
      "tensor([0.0917, 0.2313])\n",
      "tensor([-0.1382, -0.0392])\n",
      "tensor([ 0.2762, -0.1757])\n",
      "tensor([0.3252, 0.1583])\n",
      "tensor([-0.1906, -0.2373])\n",
      "tensor([0.0836, 0.3007])\n",
      "tensor([0.2097, 0.3184])\n",
      "tensor([-0.1811, -0.0582])\n",
      "tensor([-0.1234, -0.0790])\n",
      "tensor([ 0.1994, -0.0147])\n",
      "tensor([ 0.2575, -0.0803])\n",
      "tensor([0.2799, 0.0139])\n",
      "tensor([-0.2229,  0.2041])\n",
      "tensor([0.2566, 0.1749])\n",
      "tensor([0.3854, 0.1430])\n",
      "tensor([ 0.2485, -0.1766])\n",
      "tensor([-0.1898,  0.0089])\n",
      "tensor([-0.0144, -0.0278])\n",
      "tensor([-0.1454, -0.1294])\n",
      "tensor([0.0787, 0.1965])\n",
      "tensor([-0.0527,  0.0469])\n",
      "tensor([-0.0101,  0.2997])\n",
      "tensor([0.0900, 0.1800])\n",
      "tensor([-0.0725, -0.0451])\n",
      "tensor([-0.1664,  0.3309])\n",
      "tensor([0.2471, 0.0374])\n",
      "tensor([-0.3359,  0.5269])\n",
      "tensor([-0.3007, -0.3102])\n",
      "tensor([ 0.0925, -0.4331])\n",
      "tensor([ 0.3091, -0.3726])\n",
      "tensor([-0.0222, -0.4510])\n",
      "tensor([ 0.2533, -0.2549])\n",
      "tensor([ 0.0043, -0.3277])\n",
      "tensor([-0.2444,  0.1664])\n",
      "tensor([-0.1802, -0.4117])\n",
      "tensor([-0.1033,  0.2996])\n",
      "tensor([-0.0617,  0.1870])\n",
      "tensor([ 0.1913, -0.2701])\n",
      "tensor([0.1354, 0.0881])\n",
      "tensor([-0.1505,  0.0710])\n",
      "tensor([-0.2976, -0.3657])\n",
      "tensor([0.3842, 0.1385])\n",
      "tensor([-0.1469, -0.1069])\n",
      "tensor([ 0.0373, -0.1925])\n",
      "tensor([ 0.0221, -0.1826])\n",
      "tensor([-0.1431,  0.2012])\n",
      "tensor([ 0.0886, -0.0858])\n",
      "tensor([0.1596, 0.2697])\n",
      "tensor([ 0.2905, -0.1191])\n",
      "tensor([-0.1434,  0.0475])\n",
      "tensor([ 0.4001, -0.0711])\n",
      "tensor([ 0.0178, -0.2143])\n",
      "tensor([ 0.3143, -0.7023])\n",
      "tensor([-0.1577, -0.0087])\n",
      "tensor([-0.0085,  0.0708])\n",
      "tensor([-0.1336, -0.4503])\n",
      "tensor([ 0.2366, -0.0945])\n",
      "tensor([ 0.2115, -0.1955])\n",
      "tensor([0.3638, 0.2933])\n",
      "tensor([0.1366, 0.0193])\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 679/1200 (57%)\n",
      "\n",
      "tensor([-0.2573,  0.1998])\n",
      "Train Epoch: 2/100 [0/2000 (0%)]\tLoss: 0.671844\n",
      "tensor([0.1558, 0.0894])\n",
      "tensor([0.0457, 0.1539])\n",
      "tensor([-0.1598,  0.2171])\n",
      "tensor([-0.0012, -0.0752])\n",
      "tensor([ 0.0979, -0.4008])\n",
      "tensor([ 0.0552, -0.1610])\n",
      "tensor([-0.2587, -0.0453])\n",
      "tensor([-0.4262, -0.2517])\n",
      "tensor([0.4270, 0.3638])\n",
      "tensor([-0.1816,  0.3219])\n",
      "tensor([-0.3512, -0.3671])\n",
      "tensor([-0.4229, -0.1799])\n",
      "tensor([ 0.0790, -0.0804])\n",
      "tensor([-0.5694,  0.1280])\n",
      "tensor([ 0.0475, -0.2088])\n",
      "tensor([-0.0917,  0.1755])\n",
      "tensor([ 0.1400, -0.1542])\n",
      "tensor([ 0.3495, -0.1019])\n",
      "tensor([-0.3763, -0.2258])\n",
      "tensor([ 0.1005, -0.1693])\n",
      "tensor([-0.1828, -0.1767])\n",
      "tensor([0.1631, 0.3457])\n",
      "tensor([-0.1951, -0.2097])\n",
      "tensor([0.1276, 0.1997])\n",
      "tensor([ 0.1045, -0.4020])\n",
      "tensor([0.0824, 0.2406])\n",
      "tensor([ 0.1793, -0.0564])\n",
      "tensor([ 0.0100, -0.3228])\n",
      "tensor([-0.0286, -0.0595])\n",
      "tensor([ 0.2941, -0.0357])\n",
      "tensor([-0.4753, -0.5750])\n",
      "tensor([-0.2162, -0.3063])\n",
      "tensor([-0.0521, -0.0625])\n",
      "tensor([-0.0984, -0.1896])\n",
      "tensor([-0.1924,  0.1478])\n",
      "tensor([-0.2662, -0.1950])\n",
      "tensor([-0.0115,  0.2304])\n",
      "tensor([ 0.1611, -0.0310])\n",
      "tensor([-0.2007,  0.1478])\n",
      "tensor([-0.2824, -0.0532])\n",
      "tensor([-0.0406,  0.0266])\n",
      "tensor([-0.0898,  0.2918])\n",
      "tensor([-0.1661,  0.1039])\n",
      "tensor([0.1741, 0.0928])\n",
      "tensor([0.1689, 0.1395])\n",
      "tensor([0.2859, 0.3387])\n",
      "tensor([ 0.0179, -0.0003])\n",
      "tensor([-0.2993,  0.3386])\n",
      "tensor([0.0777, 0.1483])\n",
      "tensor([ 0.2932, -0.2150])\n",
      "tensor([-0.2310, -0.3626])\n",
      "tensor([-0.1047,  0.0655])\n",
      "tensor([ 0.0123, -0.0587])\n",
      "tensor([0.0831, 0.0960])\n",
      "tensor([-0.0740, -0.2866])\n",
      "tensor([-0.0005,  0.0589])\n",
      "tensor([ 0.1708, -0.2666])\n",
      "tensor([ 0.0745, -0.5147])\n",
      "tensor([ 0.0307, -0.0443])\n",
      "tensor([ 0.0238, -0.0556])\n",
      "tensor([ 0.1969, -0.2138])\n",
      "tensor([-0.1706, -0.1594])\n",
      "tensor([0.1502, 0.0164])\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 715/1200 (60%)\n",
      "\n",
      "tensor([ 0.4000, -0.0831])\n",
      "Train Epoch: 3/100 [0/2000 (0%)]\tLoss: 0.641783\n",
      "tensor([0.1474, 0.0441])\n",
      "tensor([-0.1718, -0.1042])\n",
      "tensor([ 0.0760, -0.0231])\n",
      "tensor([-0.4943, -0.1821])\n",
      "tensor([0.2083, 0.1198])\n",
      "tensor([-0.3044, -0.4603])\n",
      "tensor([0.1948, 0.1663])\n",
      "tensor([0.0075, 0.3945])\n",
      "tensor([-0.1275, -0.2454])\n",
      "tensor([0.0399, 0.2355])\n",
      "tensor([-0.1314, -0.0969])\n",
      "tensor([-0.1490, -0.1562])\n",
      "tensor([ 0.5594, -0.1368])\n",
      "tensor([-0.0264, -0.1504])\n",
      "tensor([-0.0527, -0.2419])\n",
      "tensor([-0.3457, -0.0570])\n",
      "tensor([ 0.1317, -0.0943])\n",
      "tensor([ 0.0589, -0.0666])\n",
      "tensor([-0.3931,  0.1531])\n",
      "tensor([0.3392, 0.1176])\n",
      "tensor([-0.1484,  0.1130])\n",
      "tensor([ 0.0516, -0.2509])\n",
      "tensor([-0.0483, -0.1052])\n",
      "tensor([0.0262, 0.1010])\n",
      "tensor([-0.5468, -0.0070])\n",
      "tensor([-0.0150, -0.0812])\n",
      "tensor([-0.0881,  0.0713])\n",
      "tensor([-0.1836,  0.0382])\n",
      "tensor([-0.0653,  0.1041])\n",
      "tensor([-0.6151, -0.0194])\n",
      "tensor([-0.1999,  0.2747])\n",
      "tensor([0.0399, 0.1841])\n",
      "tensor([-0.1921,  0.4761])\n",
      "tensor([ 0.1535, -0.0250])\n",
      "tensor([-0.1195, -0.0676])\n",
      "tensor([ 0.2486, -0.2971])\n",
      "tensor([-0.0934,  0.1251])\n",
      "tensor([-0.3886,  0.4374])\n",
      "tensor([-0.0404, -0.0998])\n",
      "tensor([ 0.2683, -0.1153])\n",
      "tensor([-0.1907,  0.3401])\n",
      "tensor([-0.2398, -0.2109])\n",
      "tensor([ 0.0788, -0.0503])\n",
      "tensor([ 0.0721, -0.1957])\n",
      "tensor([-0.5353,  0.0018])\n",
      "tensor([-0.1041, -0.0683])\n",
      "tensor([-0.2146,  0.1765])\n",
      "tensor([-0.0648,  0.2754])\n",
      "tensor([ 0.2381, -0.3933])\n",
      "tensor([0.1481, 0.0285])\n",
      "tensor([ 0.1941, -0.0652])\n",
      "tensor([-0.1258,  0.0899])\n",
      "tensor([-0.0223, -0.4825])\n",
      "tensor([0.3528, 0.0043])\n",
      "tensor([-0.1537, -0.0659])\n",
      "tensor([0.2839, 0.0442])\n",
      "tensor([0.0149, 0.3321])\n",
      "tensor([ 0.0867, -0.0031])\n",
      "tensor([0.0824, 0.5953])\n",
      "tensor([ 0.3404, -0.1402])\n",
      "tensor([-0.0914, -0.1225])\n",
      "tensor([0.2312, 0.5799])\n",
      "tensor([ 0.2576, -0.3261])\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 735/1200 (61%)\n",
      "\n",
      "tensor([-0.1660,  0.0531])\n",
      "Train Epoch: 4/100 [0/2000 (0%)]\tLoss: 0.662560\n",
      "tensor([-0.1384, -0.1068])\n",
      "tensor([0.1617, 0.0132])\n",
      "tensor([ 0.4341, -0.1362])\n",
      "tensor([0.2158, 0.0035])\n",
      "tensor([0.0113, 0.2976])\n",
      "tensor([0.0461, 0.2996])\n",
      "tensor([0.0328, 0.1533])\n",
      "tensor([-0.2111, -0.1394])\n",
      "tensor([-0.0164,  0.0544])\n",
      "tensor([-0.0898,  0.3226])\n",
      "tensor([-0.2244, -0.0387])\n",
      "tensor([-0.2733,  0.1837])\n",
      "tensor([ 0.4395, -0.0925])\n",
      "tensor([ 0.0498, -0.5085])\n",
      "tensor([0.0292, 0.4383])\n",
      "tensor([-0.2520, -0.4543])\n",
      "tensor([-0.3374,  0.2961])\n",
      "tensor([ 0.3094, -0.0327])\n",
      "tensor([ 0.0825, -0.0342])\n",
      "tensor([ 0.0889, -0.1155])\n",
      "tensor([-0.2034, -0.1817])\n",
      "tensor([-0.1537,  0.2745])\n",
      "tensor([0.1919, 0.0942])\n",
      "tensor([ 0.0653, -0.1718])\n",
      "tensor([-0.2129,  0.0062])\n",
      "tensor([ 0.0191, -0.0957])\n",
      "tensor([-0.2823,  0.3036])\n",
      "tensor([-0.2541,  0.0914])\n",
      "tensor([-0.1388, -0.0236])\n",
      "tensor([0.0523, 0.0890])\n",
      "tensor([0.0452, 0.0098])\n",
      "tensor([-0.0280,  0.0610])\n",
      "tensor([0.1613, 0.2040])\n",
      "tensor([ 0.0079, -0.0396])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1028,  0.1047])\n",
      "tensor([-0.5436,  0.0224])\n",
      "tensor([-0.0150, -0.0274])\n",
      "tensor([0.0546, 0.4162])\n",
      "tensor([-0.1689, -0.0807])\n",
      "tensor([-0.1219,  0.0825])\n",
      "tensor([-0.2460, -0.2334])\n",
      "tensor([-0.1049,  0.0311])\n",
      "tensor([-0.2416, -0.1245])\n",
      "tensor([-0.0455,  0.3503])\n",
      "tensor([-0.3364,  0.1479])\n",
      "tensor([-0.3502, -0.1620])\n",
      "tensor([0.2855, 0.1835])\n",
      "tensor([0.1900, 0.1576])\n",
      "tensor([ 0.3597, -0.0682])\n",
      "tensor([0.5920, 0.2266])\n",
      "tensor([-0.1606, -0.1046])\n",
      "tensor([-0.0165,  0.3467])\n",
      "tensor([-0.1046, -0.5305])\n",
      "tensor([-0.6196,  0.1370])\n",
      "tensor([-0.2635, -0.0236])\n",
      "tensor([-0.1739, -0.1579])\n",
      "tensor([-0.4512, -0.2809])\n",
      "tensor([0.3019, 0.1637])\n",
      "tensor([0.0138, 0.2126])\n",
      "tensor([ 0.1390, -0.2071])\n",
      "tensor([0.1081, 0.2030])\n",
      "tensor([0.0072, 0.4914])\n",
      "tensor([ 0.2359, -0.0129])\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 715/1200 (60%)\n",
      "\n",
      "tensor([0.1346, 0.1498])\n",
      "Train Epoch: 5/100 [0/2000 (0%)]\tLoss: 0.684949\n",
      "tensor([ 0.4373, -0.4670])\n",
      "tensor([0.2092, 0.2250])\n",
      "tensor([0.0407, 0.0118])\n",
      "tensor([-0.5206, -0.0470])\n",
      "tensor([0.0543, 0.3602])\n",
      "tensor([-0.1907,  0.2609])\n",
      "tensor([-0.4294,  0.2191])\n",
      "tensor([0.0861, 0.0394])\n",
      "tensor([-0.0683,  0.1228])\n",
      "tensor([-0.6972, -0.0946])\n",
      "tensor([ 0.2433, -0.2185])\n",
      "tensor([-0.0385, -0.1073])\n",
      "tensor([0.0754, 0.0029])\n",
      "tensor([ 0.1060, -0.1352])\n",
      "tensor([ 0.0313, -0.2574])\n",
      "tensor([-0.2947, -0.0761])\n",
      "tensor([ 0.0960, -0.3647])\n",
      "tensor([-0.0545, -0.2117])\n",
      "tensor([-0.1452, -0.4015])\n",
      "tensor([ 0.1083, -0.3142])\n",
      "tensor([ 0.6598, -0.0444])\n",
      "tensor([-0.0285,  0.2719])\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch, dataloader['train'])\n",
    "    curr_acc = test(dataloader['test'])\n",
    "    acc.append(curr_acc)\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curr_acc = test(dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"stn_lenet_baseline.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(dataloader['test']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "transform_in(data[0][0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.stn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=1\n",
    "with torch.no_grad():\n",
    "    cat, theta, z = model(data)\n",
    "cat = torch.argmax(F.softmax(cat),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#theta = torch.cat((model.downscale.unsqueeze(0).repeat(\n",
    "#            theta.size(0), 1, 1), theta.unsqueeze(2)),\n",
    "#                          dim=2)\n",
    "        \n",
    "        #theta = theta.view(-1, 2, 3)\n",
    "for num in range(50):\n",
    "    plt.figure(figsize=(5,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    img = data[num:num+1,...]   \n",
    "    th = theta[num:num+1,...]\n",
    "    #theta[0,:,2] = torch.FloatTensor((0,.5))\n",
    "    #print(th)\n",
    "    grid_size = torch.Size([1, 3, 28, 28])\n",
    "    grid = F.affine_grid(th, grid_size)\n",
    "    img_grid = F.grid_sample(img, grid)\n",
    "    plt.imshow(data[num,...].permute(1,2,0).detach().numpy())\n",
    "    plt.title(str(num)+', '+str(label[num]))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img_grid[0,:].permute(1,2,0).detach().numpy())\n",
    "    plt.plot(14,14,'r+')\n",
    "    plt.title(cat[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#theta = torch.cat((model.downscale.unsqueeze(0).repeat(\n",
    "#            theta.size(0), 1, 1), theta.unsqueeze(2)),\n",
    "#                          dim=2)\n",
    "mem_z  = []\n",
    "mem_cat  = []\n",
    "\n",
    "        #theta = theta.view(-1, 2, 3)\n",
    "for num in [43,]*50: #range(50):\n",
    "    with torch.no_grad():\n",
    "        #img = data[0][num,...].unsqueeze(0)\n",
    "        #polo_img = {'in': data[1]['in'][num,...].unsqueeze(0),\n",
    "        #             'out': data[1]['out'][num,...].unsqueeze(0)}\n",
    "        cat, theta, z = model(data)\n",
    "    cat = torch.argmax(F.softmax(cat),1)\n",
    "    plt.figure(figsize=(5,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    img = data[num:num+1,...]   \n",
    "    th = theta[num:num+1,...]\n",
    "    mem_z.append(z)\n",
    "    mem_cat.append(cat)\n",
    "    #theta[0,:,2] = torch.FloatTensor((0,.5))\n",
    "    #print(th)\n",
    "    grid_size = torch.Size([1, 3, 28, 28])\n",
    "    grid = F.affine_grid(th, grid_size)\n",
    "    img_grid = F.grid_sample(img, grid)\n",
    "    plt.imshow(data[num,...].permute(1,2,0).detach().numpy())\n",
    "    plt.title(label[num])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img_grid[0,:].permute(1,2,0).detach().numpy())\n",
    "    plt.plot(14,14,'r+')\n",
    "    plt.title(cat[num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for num in range(batch_size):\n",
    "    plt.figure()\n",
    "    plt.imshow(data[num,...].permute(1,2,0).detach().numpy())\n",
    "    for i, z in enumerate(mem_z):\n",
    "        if mem_cat[i][num] == 1:\n",
    "            plt.plot(127.5 + z[num][0]*128, 127.5 + z[num][1]*128,'r+')\n",
    "        else:\n",
    "            plt.plot(127.5 + z[num][0]*128, 127.5 + z[num][1]*128,'b+')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
